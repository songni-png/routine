import streamlit as st
import pandas as pd
from datetime import datetime
from streamlit_js_eval import streamlit_js_eval
from geopy.distance import geodesic
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import requests
import os

API_KEY = "db993432d1b5f597ea03fd182d005ce9"

st.set_page_config(page_title="íšŒë³µ ë£¨í‹´ ì¶”ì²œê¸°", page_icon="ğŸ§˜", layout="centered")
st.title("ğŸ§˜ íšŒë³µì´ í•„ìš”í•œ ë‚ ì„ ìœ„í•œ ë§ì¶¤ ë£¨í‹´ ì¶”ì²œê¸°")
st.markdown(f"â° í˜„ì¬ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M')}")

loc = streamlit_js_eval(
    js_expressions="""
        new Promise((resolve, reject) => {
            navigator.geolocation.getCurrentPosition(
                (pos) => resolve({ latitude: pos.coords.latitude, longitude: pos.coords.longitude }),
                (err) => reject(err)
            );
        })
    """,
    key="get_location",
    label="ìœ„ì¹˜ ê¶Œí•œ ìš”ì²­"
)

if loc and isinstance(loc, dict) and "latitude" in loc:
    lat, lon = loc["latitude"], loc["longitude"]
    st.success(f"ğŸ“ í˜„ì¬ ìœ„ì¹˜: ìœ„ë„ {lat:.5f}, ê²½ë„ {lon:.5f}")
else:
    st.warning("ğŸ“¡ ìœ„ì¹˜ ê¶Œí•œì´ í—ˆìš©ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    lat, lon = None, None

radius = st.slider("ì¶”ì²œ ë°˜ê²½ (km)", 1.0, 5.0, 2.5, step=0.1)

# â–¶ ë°ì´í„° íŒŒì¼ ê²½ë¡œ ì„¤ì •
current_dir = os.path.dirname(os.path.abspath(__file__))
PLACE_FILE = os.path.join(current_dir, "ì¥ì†Œ_ì¹´í…Œê³ ë¦¬_ìµœì¢…ë¶„ë¥˜.csv")
CLICK_FILE = os.path.join(current_dir, "click_log.csv")


try:
    df = pd.read_csv(PLACE_FILE, encoding="cp949")
    df = df.dropna(subset=["LAT", "LON", "CATEGORY"])
    df["LAT"] = df["LAT"].astype(float)
    df["LON"] = df["LON"].astype(float)
    df["TAG"] = df["TAG"].fillna("")
except Exception as e:
    st.error(f"âŒ ì¥ì†Œ íŒŒì¼ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
    st.stop()

# ğŸ“ ê±°ë¦¬ ê³„ì‚° í•¨ìˆ˜ (float ë°˜í™˜)
def compute_distance(row):
    return geodesic((lat, lon), (row["LAT"], row["LON"])).km if lat and lon else None

# â˜ï¸ ë‚ ì”¨ API
@st.cache_data
def get_weather(lat, lon):
    try:
        url = "https://api.openweathermap.org/data/2.5/weather"
        params = {"lat": lat, "lon": lon, "appid": API_KEY, "units": "metric", "lang": "kr"}
        res = requests.get(url, params=params)
        data = res.json()
        return {
            "weather": data["weather"][0]["description"],
            "temp": data["main"]["temp"],
            "humidity": data["main"]["humidity"]
        }
    except:
        return {"weather": "ì—ëŸ¬", "temp": "-", "humidity": "-"}

# TF-IDF ìœ ì‚¬ë„ ê³„ì‚°
df["feature_text"] = df["CATEGORY"] + " " + df["TAG"]
vectorizer = TfidfVectorizer()
tfidf_matrix = vectorizer.fit_transform(df["feature_text"])

def get_similar_categories(category):
    cat_index = df[df["CATEGORY"] == category].index[0]
    cat_vector = tfidf_matrix[cat_index]
    similarity_scores = cosine_similarity(cat_vector, tfidf_matrix).flatten()
    similar_cats = df.iloc[similarity_scores.argsort()[-4:-1][::-1]]["CATEGORY"].unique().tolist()
    return similar_cats

try:
    log_df = pd.read_csv(CLICK_FILE, encoding="cp949", on_bad_lines='skip')
    top_cats_series = log_df['category'].value_counts().head(3)
    top_cats = top_cats_series.index.tolist()
    similar_top_cats = []
    for cat in top_cats:
        similar_top_cats.extend(get_similar_categories(cat))
    similar_top_cats = list(set(similar_top_cats))
except Exception as e:
    st.error(f"âŒ í´ë¦­ ë¡œê·¸ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
    top_cats_series = pd.Series()
    top_cats = []
    similar_top_cats = []

if not top_cats_series.empty:
    st.markdown("### â­ ìì£¼ ì„ íƒëœ ì¹´í…Œê³ ë¦¬ ë° ìœ ì‚¬ ì¹´í…Œê³ ë¦¬")
    for cat, count in top_cats_series.items():
        st.markdown(f"- {cat} (ì„ íƒ {count}íšŒ)")

if st.button("ì¹´í…Œê³ ë¦¬ë³„ ëœë¤ ì¥ì†Œ ì¶”ì²œë°›ê¸°") and lat and lon:
    df["DIST_KM"] = df.apply(compute_distance, axis=1)
    nearby_df = df[df["DIST_KM"] <= radius]
    if nearby_df.empty:
        st.warning("âŒ ì¡°ê±´ì— ë§ëŠ” ì¥ì†Œê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        sampled_df = nearby_df.groupby("CATEGORY", group_keys=False).apply(lambda x: x.sample(1)).reset_index(drop=True)
        sampled_df["cat_order"] = sampled_df["CATEGORY"].apply(lambda x: top_cats.index(x) if x in top_cats else 99)
        sampled_df = sampled_df.sort_values("cat_order").drop(columns="cat_order")

        st.session_state["recommendation"] = sampled_df
        st.session_state["filtered"] = nearby_df
        st.session_state["click_count"] = st.session_state.get("click_count", 0) + 1

sampled_df = st.session_state.get("recommendation")
filtered_df = st.session_state.get("filtered")
click_count = st.session_state.get("click_count", 0)

if isinstance(sampled_df, pd.DataFrame) and not sampled_df.empty:
    weather = get_weather(lat, lon)
    st.markdown("### ğŸŒ¤ï¸ í˜„ì¬ ìœ„ì¹˜ì˜ ë‚ ì”¨")
    st.write(f"- ë‚ ì”¨ ìƒíƒœ: {weather['weather']}")
    st.write(f"- ê¸°ì˜¨: {weather['temp']}Â°C")
    st.write(f"- ìŠµë„: {weather['humidity']}%")
    st.map(sampled_df.rename(columns={"LAT": "lat", "LON": "lon"}))

    for _, row in sampled_df.iterrows():
        with st.container():
            st.markdown(f"#### ğŸ·ï¸ **{row['NAME']}**")
            st.markdown(f"**ì¹´í…Œê³ ë¦¬:** {row['CATEGORY']}")
            st.markdown(f"ğŸ“ ìœ„ì¹˜: {row['LOCATION']}")
            st.markdown(f"ğŸ·ï¸ íƒœê·¸: {row.get('TAG', 'ì—†ìŒ')}")
            st.markdown(f"ğŸ§­ ê±°ë¦¬: {row['DIST_KM']:.2f} km")

            col1, col2 = st.columns([1, 2])

            with col1:
                if st.button(f"ğŸ” ìƒì„¸ ë³´ê¸°", key=f"detail_{row['NAME']}"):
                    # ì¤‘ë³µ í´ë¦­ ë°©ì§€: ë‹¹ì¼ ì´ë¯¸ í´ë¦­í•œ ê²½ìš° ë¬´ì‹œ
                    today = datetime.now().strftime("%Y-%m-%d")
                    if os.path.exists(CLICK_FILE):
                        clicks_today = pd.read_csv(CLICK_FILE, encoding="utf-8-sig", on_bad_lines='skip')
                        already_clicked = not clicks_today[
                            (clicks_today["name"] == row["NAME"]) &
                            (clicks_today["timestamp"].str.startswith(today))
                        ].empty
                    else:
                        already_clicked = False

                    if already_clicked:
                        st.info(f"âš ï¸ ì˜¤ëŠ˜ ì´ë¯¸ '{row['NAME']}'ì„(ë¥¼) í´ë¦­í•˜ì…¨ìŠµë‹ˆë‹¤.")
                    else:
                        new_log = {
                            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                            "user_id": "user1",
                            "name": row["NAME"],
                            "category": row["CATEGORY"]
                        }
                        pd.DataFrame([new_log]).to_csv(
                            CLICK_FILE, mode="a", index=False,
                            header=not os.path.exists(CLICK_FILE),
                            encoding="utf-8-sig"
                        )
                        st.success(f"âœ… '{row['NAME']}' í´ë¦­ ê¸°ë¡ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

            with col2:
                if click_count >= 2 and row["CATEGORY"] in top_cats:
                    if st.button(f"[ğŸ” {row['CATEGORY']}] ê´€ë ¨ ì¥ì†Œ ë”ë³´ê¸°", key=f"more_{row['CATEGORY']}"):
                        related_df = filtered_df[
                            (filtered_df["CATEGORY"] == row["CATEGORY"]) & 
                            (filtered_df["NAME"] != row["NAME"])
                        ]
                        st.markdown(f"##### ğŸ“Œ ë°˜ê²½ {radius}km ì´ë‚´ì˜ '{row['CATEGORY']}' ì¹´í…Œê³ ë¦¬ ì¥ì†Œ:")
                        if not related_df.empty:
                            for _, r in related_df.iterrows():
                                st.markdown(f"- **{r['NAME']}** ({r['LOCATION']}, {r['TAG']})")
                        else:
                            st.info("ğŸš« ì¶”ê°€ë¡œ í‘œì‹œí•  ì¥ì†Œê°€ ì—†ìŠµë‹ˆë‹¤.")
        st.markdown("---")
else:
    st.info("â³ ë¨¼ì € 'ì¹´í…Œê³ ë¦¬ë³„ ëœë¤ ì¥ì†Œ ì¶”ì²œë°›ê¸°' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")

# í˜‘ì—… ì¶”ì²œ
if os.path.exists(CLICK_FILE):
    try:
        log_df = pd.read_csv(CLICK_FILE, encoding="utf-8-sig", on_bad_lines='skip')
        st.markdown("## ğŸ—‚ï¸ ë‚´ê°€ í´ë¦­í•œ ì¥ì†Œ ê¸°ë¡")
        st.dataframe(log_df.tail(10))

        if not log_df.empty and "name" in log_df.columns:
            user_place = pd.pivot_table(log_df, index="user_id", columns="name", aggfunc="size", fill_value=0)
            if user_place.shape[0] > 1:
                sim_scores = cosine_similarity(user_place, user_place)
                sim_df = pd.DataFrame(sim_scores, index=user_place.index, columns=user_place.index)
                recent_user = log_df["user_id"].iloc[-1]
                if recent_user in sim_df.index:
                    recs = sim_df.loc[recent_user].sort_values(ascending=False).drop(recent_user).head(3).index.tolist()
                    recommended_names = log_df[log_df["user_id"].isin(recs)]["name"].value_counts().head(3).index.tolist()
                    st.markdown("## ğŸ‘¥ ë‹¹ì‹ ê³¼ ë¹„ìŠ·í•œ ì‚¬ëŒë“¤ì´ ìì£¼ ì„ íƒí•œ ì¥ì†Œ")
                    for r in recommended_names:
                        info = df[df["NAME"] == r]
                        if not info.empty:
                            info = info.iloc[0]
                            st.markdown(f"### â­ {r}")
                            st.markdown(f"- ì¹´í…Œê³ ë¦¬: {info['CATEGORY']}")
                            st.markdown(f"- ìœ„ì¹˜: {info['LOCATION']}")
                            st.markdown(f"- ê±°ë¦¬: {compute_distance(info):.2f} km")
                            st.markdown("---")
    except Exception as e:
        st.error(f"âŒ í´ë¦­ ê¸°ë¡ í…Œì´ë¸” ë¶ˆëŸ¬ì˜¤ê¸° ì˜¤ë¥˜: {e}")
